{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53bef7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "text = \"Python 3.0, released in 2008, was a major revision of the language that is not completely backward-compatible. Many Python 2 programs do not run unmodified on Python\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda91b85",
   "metadata": {},
   "source": [
    "# text normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2f92951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.0, released in 2008, was a major revision of the language that is not completely backward-compatible. many python 2 programs do not run unmodified on python\n"
     ]
    }
   ],
   "source": [
    "# to lowercase\n",
    "text_lower = text.lower()\n",
    "print(text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8866626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python  released in  was a major revision of the language that is not completely backwardcompatible many python  programs do not run unmodified on python'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing numbers and punctuation\n",
    "text_cleaned = ''.join(char for char in text_lower if char.isalpha() or char.isspace())\n",
    "text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7d4ad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'released',\n",
       " 'major',\n",
       " 'revision',\n",
       " 'language',\n",
       " 'completely',\n",
       " 'backwardcompatible',\n",
       " 'many',\n",
       " 'python',\n",
       " 'programs',\n",
       " 'run',\n",
       " 'unmodified',\n",
       " 'python']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words\n",
    "#%pip install nltk\n",
    "text_cleaned2 = text_cleaned.split()\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "text_no_stopwords = [word for word in text_cleaned2 if word not in stop_words]\n",
    "text_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be617360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'released',\n",
       " 'major',\n",
       " 'revision',\n",
       " 'language',\n",
       " 'completely',\n",
       " 'backwardcompatible',\n",
       " 'many',\n",
       " 'python',\n",
       " 'program',\n",
       " 'run',\n",
       " 'unmodified',\n",
       " 'python']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "text_lemmatized = [lemmatizer.lemmatize(word) for word in text_no_stopwords]\n",
    "text_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd54b1b",
   "metadata": {},
   "source": [
    "# reflectie\n",
    "### welke woorden verwijnen er?\n",
    "+ cijfers, woorden als a, opvulwoorden als completely\n",
    "\n",
    "\n",
    "### waarom is dit nuttig?\n",
    "+ omdat zo makkelijker, en efficienter met data wordt omgegaan om zo een sneller een response te krijgen zonder teveel tijd of resources te gebruiken denk ik?\n",
    "\n",
    "### welke informatie kan er verloren gaan?\n",
    "+ informatie als bijvoorbeeld in dit geval python programmas NIET unmodified kunnen runnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b140f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1c47a",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7fe5494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\yazan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75bb20b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'released', 'major', 'revision', 'language', 'completely', 'backwardcompatible', 'many', 'python', 'program', 'run', 'unmodified', 'python']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'python': 3,\n",
       "         'released': 1,\n",
       "         'major': 1,\n",
       "         'revision': 1,\n",
       "         'language': 1,\n",
       "         'completely': 1,\n",
       "         'backwardcompatible': 1,\n",
       "         'many': 1,\n",
       "         'program': 1,\n",
       "         'run': 1,\n",
       "         'unmodified': 1})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(' '.join(text_lemmatized))\n",
    "print(tokens)\n",
    "# token counts\n",
    "from collections import Counter\n",
    "token_counts = Counter(tokens)\n",
    "token_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1a2961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>released</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>major</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>completely</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>backwardcompatible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>many</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>program</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unmodified</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Token  Count\n",
       "0               python      3\n",
       "1             released      1\n",
       "2                major      1\n",
       "3             revision      1\n",
       "4             language      1\n",
       "5           completely      1\n",
       "6   backwardcompatible      1\n",
       "7                 many      1\n",
       "8              program      1\n",
       "9                  run      1\n",
       "10          unmodified      1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency table\n",
    "freq_table = pd.DataFrame(token_counts.items(), columns=['Token', 'Count'])\n",
    "freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93bbb693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python 3.0, released in 2008, was a major revision of the language that is not completely backward-compatible.',\n",
       " 'Many Python 2 programs do not run unmodified on Python']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra challenge: tokenize text with nltk.sent_tokenize() and check how python recognizes sentences.\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e738584",
   "metadata": {},
   "source": [
    "# step 3 textrepresentatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd4cd415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 3 1 1 1 1]]\n",
      "['backwardcompatible' 'completely' 'language' 'major' 'many' 'program'\n",
      " 'python' 'released' 'revision' 'run' 'unmodified']\n"
     ]
    }
   ],
   "source": [
    "# step 3 textrepresentatie\n",
    "# use the same text and create 2 representations \n",
    "# 1. Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform([' '.join(text_lemmatized)])\n",
    "print(X_bow.toarray())\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "edf9ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_backwardcompatible' 'x0_completely' 'x0_language' 'x0_major'\n",
      " 'x0_many' 'x0_program' 'x0_python' 'x0_released' 'x0_revision' 'x0_run'\n",
      " 'x0_unmodified']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_ohe = encoder.fit_transform(np.array(text_lemmatized).reshape(-1, 1))\n",
    "print(encoder.get_feature_names_out())\n",
    "X_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf50f1",
   "metadata": {},
   "source": [
    "# reflectie\n",
    "\n",
    "### verschil? \n",
    "+ bag of words maakt een vector representatie van het hele document, telt alle occurences van elk woord.\n",
    "+ one hot encoding maakt een binary vector voor elk uniek woord, laat zien of een woord er is of niet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d65fd8",
   "metadata": {},
   "source": [
    "# stap 4 vergelijkings tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36b3386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Keeps Order of Words in Vocabulary</th>\n",
       "      <th>Uses Frequency Counts</th>\n",
       "      <th>Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Vector representation counting occurrences of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Hot Encoding</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Binary vector indicating presence or absence o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Representation  Keeps Order of Words in Vocabulary  \\\n",
       "0      Bag of Words                               False   \n",
       "1  One Hot Encoding                               False   \n",
       "\n",
       "   Uses Frequency Counts                                     Interpretation  \n",
       "0                   True  Vector representation counting occurrences of ...  \n",
       "1                  False  Binary vector indicating presence or absence o...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison table one hot encoding vs bag of words\n",
    "# keeps order of words in vocabulary?\n",
    "# uses frequency counts?\n",
    "# interpretation?\n",
    "comparison_table = pd.DataFrame({\n",
    "    'Representation': ['Bag of Words', 'One Hot Encoding'],\n",
    "    'Keeps Order of Words in Vocabulary': [False, False],\n",
    "    'Uses Frequency Counts': [True, False],\n",
    "    'Interpretation': [\n",
    "        'Vector representation counting occurrences of each word',\n",
    "        'Binary vector indicating presence or absence of each unique word'\n",
    "    ]\n",
    "})\n",
    "comparison_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
